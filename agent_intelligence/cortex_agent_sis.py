"""
Cortex Agent & Intelligence Demo App for Snowflake China Region
Streamlit in Snowflake (SiS) ç‰ˆæœ¬
ä½¿ç”¨ Qwen API æ¨¡æ‹Ÿ Cortex Agent å’Œ Cortex Intelligence åŠŸèƒ½
æ”¯æŒè¯­ä¹‰æ¨¡å‹ (Semantic Model) æ¥å¢å¼º SQL ç”Ÿæˆæ•ˆæœ
"""

import json
import uuid
import pandas as pd
import streamlit as st
from datetime import datetime
from typing import Any, Dict, List, Optional

# è®¾ç½®é¡µé¢é…ç½®
st.set_page_config(
    layout="wide",
    page_icon="â„ï¸",
    page_title="Snowflake China Intelligence",
    initial_sidebar_state="expanded"
)

# SiS ç¯å¢ƒæ£€æµ‹å’Œè¿æ¥
def get_snowflake_connection():
    """è·å– Snowflake è¿æ¥"""
    from snowflake.snowpark.context import get_active_session
    session = get_active_session()
    return session.connection

def get_snowpark_session():
    """è·å– Snowpark Session"""
    from snowflake.snowpark.context import get_active_session
    return get_active_session()

# ===============================
# æ ·å¼å®šä¹‰
# ===============================
CUSTOM_CSS = """
<style>
@import url('https://fonts.googleapis.com/css2?family=JetBrains+Mono:wght@400;500;600&family=Noto+Sans+SC:wght@300;400;500;700&display=swap');

:root {
    --primary-gradient: linear-gradient(135deg, #00D4FF 0%, #7B2CBF 50%, #FF6B6B 100%);
    --card-bg: rgba(17, 25, 40, 0.75);
    --border-color: rgba(255, 255, 255, 0.125);
    --text-primary: #E8E8E8;
    --text-secondary: #A0A0A0;
    --accent-cyan: #00D4FF;
    --accent-purple: #7B2CBF;
    --accent-pink: #FF6B6B;
}

.main {
    background: linear-gradient(135deg, #0a0a1a 0%, #1a1a2e 50%, #16213e 100%);
    font-family: 'Noto Sans SC', 'JetBrains Mono', sans-serif;
}

.stApp {
    background: linear-gradient(135deg, #0a0a1a 0%, #1a1a2e 50%, #16213e 100%);
}

.main-title {
    background: var(--primary-gradient);
    -webkit-background-clip: text;
    -webkit-text-fill-color: transparent;
    background-clip: text;
    font-size: 2.5rem;
    font-weight: 700;
    text-align: center;
    margin-bottom: 0.5rem;
}

.subtitle {
    color: var(--text-secondary);
    text-align: center;
    font-size: 1rem;
    margin-bottom: 2rem;
}

.feature-card {
    background: var(--card-bg);
    backdrop-filter: blur(16px);
    border: 1px solid var(--border-color);
    border-radius: 16px;
    padding: 1.5rem;
    margin: 1rem 0;
}

.agent-message {
    background: linear-gradient(135deg, rgba(0, 212, 255, 0.1) 0%, rgba(123, 44, 191, 0.1) 100%);
    border-left: 3px solid var(--accent-cyan);
    border-radius: 0 12px 12px 0;
    padding: 1rem 1.25rem;
    margin: 0.75rem 0;
}

.user-message {
    background: rgba(255, 107, 107, 0.1);
    border-right: 3px solid var(--accent-pink);
    border-radius: 12px 0 0 12px;
    padding: 1rem 1.25rem;
    margin: 0.75rem 0;
    text-align: right;
}

.tool-card {
    background: rgba(123, 44, 191, 0.15);
    border: 1px solid rgba(123, 44, 191, 0.3);
    border-radius: 8px;
    padding: 0.75rem 1rem;
    margin: 0.5rem 0;
    font-family: 'JetBrains Mono', monospace;
    font-size: 0.85rem;
}

.semantic-badge {
    background: linear-gradient(135deg, #00D4FF 0%, #7B2CBF 100%);
    color: white;
    padding: 0.25rem 0.75rem;
    border-radius: 20px;
    font-size: 0.8rem;
    font-weight: 500;
}

.metric-card {
    background: var(--card-bg);
    border: 1px solid var(--border-color);
    border-radius: 12px;
    padding: 1.25rem;
    text-align: center;
}

.metric-value {
    font-size: 2rem;
    font-weight: 700;
    background: var(--primary-gradient);
    -webkit-background-clip: text;
    -webkit-text-fill-color: transparent;
}

.metric-label {
    color: var(--text-secondary);
    font-size: 0.9rem;
}
</style>
"""

# ===============================
# æ¨¡å‹æä¾›å•†å’Œæ¨¡å‹é…ç½®
# ===============================
MODEL_PROVIDERS = {
    "DashScope (é€šä¹‰åƒé—®)": {
        "models": {
            "qwen-max": "Qwen-Max (æ¨èï¼Œèƒ½åŠ›æœ€å¼º)",
            "qwen-plus": "Qwen-Plus (å¹³è¡¡æ€§èƒ½ä¸æˆæœ¬)",
            "qwen-turbo": "Qwen-Turbo (å¿«é€Ÿå“åº”)",
            "qwen-max-longcontext": "Qwen-Max-LongContext (é•¿æ–‡æœ¬)",
            "qwen2.5-72b-instruct": "Qwen2.5-72B-Instruct",
            "qwen2.5-32b-instruct": "Qwen2.5-32B-Instruct",
        },
        "default": "qwen-max"
    },
    "DeepSeek": {
        "models": {
            "deepseek-chat": "DeepSeek-V3 (æ¨è)",
            "deepseek-reasoner": "DeepSeek-R1 (æ·±åº¦æ¨ç†)",
        },
        "default": "deepseek-chat"
    },
    "Kimi (æœˆä¹‹æš—é¢)": {
        "models": {
            "moonshot-v1-8k": "Moonshot-v1-8K",
            "moonshot-v1-32k": "Moonshot-v1-32K",
            "moonshot-v1-128k": "Moonshot-v1-128K (é•¿æ–‡æœ¬)",
        },
        "default": "moonshot-v1-8k"
    },
    "MiniMax": {
        "models": {
            "abab6.5s-chat": "ABAB6.5s (å¿«é€Ÿ)",
            "abab6.5-chat": "ABAB6.5 (æ ‡å‡†)",
            "abab5.5-chat": "ABAB5.5",
        },
        "default": "abab6.5s-chat"
    },
}

DEFAULT_PROVIDER = "DashScope (é€šä¹‰åƒé—®)"
DEFAULT_MODEL = "qwen-max"


# ===============================
# æ—¶é—´é—®å€™è¯­ç”Ÿæˆ (ä¸­å›½æ—¶åŒº UTC+8)
# ===============================
def get_time_greeting(username: str = "Yuheng") -> tuple[str, str]:
    """æ ¹æ®ä¸­å›½æ—¶åŒºæ—¶é—´ç”Ÿæˆé—®å€™è¯­"""
    from datetime import timezone, timedelta
    
    # ä¸­å›½æ—¶åŒº UTC+8
    china_tz = timezone(timedelta(hours=8))
    china_time = datetime.now(china_tz)
    current_hour = china_time.hour
    
    if 5 <= current_hour < 12:
        greeting = f"Good morning, {username}"
        greeting_cn = f"æ—©ä¸Šå¥½ï¼Œ{username}"
    elif 12 <= current_hour < 14:
        greeting = f"Good afternoon, {username}"
        greeting_cn = f"ä¸­åˆå¥½ï¼Œ{username}"
    elif 14 <= current_hour < 18:
        greeting = f"Good afternoon, {username}"
        greeting_cn = f"ä¸‹åˆå¥½ï¼Œ{username}"
    elif 18 <= current_hour < 22:
        greeting = f"Good evening, {username}"
        greeting_cn = f"æ™šä¸Šå¥½ï¼Œ{username}"
    else:
        greeting = f"Good night, {username}"
        greeting_cn = f"å¤œæ·±äº†ï¼Œ{username}"
    
    return greeting, greeting_cn


# ===============================
# Qwen API è°ƒç”¨ (é€šè¿‡ Snowflake UDF)
# ===============================

def call_qwen_udf(conn, model: str, prompt: str, system_prompt: str = None) -> str:
    """é€šè¿‡ Snowflake UDF è°ƒç”¨ Qwen API"""
    escaped_prompt = prompt.replace("'", "''").replace("\\", "\\\\")
    
    if system_prompt:
        escaped_system = system_prompt.replace("'", "''").replace("\\", "\\\\")
        full_prompt = f"[ç³»ç»ŸæŒ‡ä»¤]: {escaped_system}\n\n[ç”¨æˆ·é—®é¢˜]: {escaped_prompt}"
    else:
        full_prompt = escaped_prompt
    
    query = f"SELECT SNOWFLAKE_PROD_USER1.CORTEX_ANALYST.QWEN_COMPLETE('{model}', $${full_prompt}$$)"
    
    try:
        cursor = conn.cursor()
        cursor.execute(query)
        result = cursor.fetchone()
        if result and result[0]:
            return result[0]
        return ""
    except Exception as e:
        return f"é”™è¯¯: {str(e)}"


# ===============================
# è¯­ä¹‰æ¨¡å‹ç®¡ç†
# ===============================
def load_semantic_model_from_stage(conn, stage_path: str) -> Optional[str]:
    """ä» Stage åŠ è½½è¯­ä¹‰æ¨¡å‹ YAML"""
    try:
        session = get_snowpark_session()
        # è·å– YAML å†…å®¹
        yaml_content = session.file.get_stream(stage_path).read().decode('utf-8')
        return yaml_content
    except Exception as e:
        st.warning(f"æ— æ³•åŠ è½½è¯­ä¹‰æ¨¡å‹: {e}")
        return None

def list_yaml_files_in_stage(conn, stage_name: str) -> List[str]:
    """åˆ—å‡º Stage ä¸­çš„ YAML æ–‡ä»¶"""
    try:
        cursor = conn.cursor()
        cursor.execute(f"LIST @{stage_name}")
        files = []
        for row in cursor.fetchall():
            file_name = row[0]
            if file_name.endswith('.yaml') or file_name.endswith('.yml'):
                files.append(file_name)
        return files
    except Exception as e:
        return []

def parse_semantic_model(yaml_content: str) -> Dict[str, Any]:
    """è§£æè¯­ä¹‰æ¨¡å‹ YAML ä¸ºç»“æ„åŒ–æ•°æ®"""
    try:
        import yaml
        model = yaml.safe_load(yaml_content)
        return model
    except Exception:
        # ç®€å•è§£æ
        return {"raw": yaml_content}

def format_semantic_model_for_prompt(yaml_content: str) -> str:
    """æ ¼å¼åŒ–è¯­ä¹‰æ¨¡å‹ç”¨äº LLM æç¤º"""
    return f"""
## è¯­ä¹‰æ¨¡å‹å®šä¹‰ (YAML)

ä»¥ä¸‹æ˜¯æ•°æ®çš„è¯­ä¹‰æ¨¡å‹ï¼ŒåŒ…å«äº†è¡¨ç»“æ„ã€ä¸šåŠ¡å«ä¹‰ã€æŒ‡æ ‡å®šä¹‰å’Œå…³ç³»ï¼š

```yaml
{yaml_content}
```

è¯·æ ¹æ®è¿™ä¸ªè¯­ä¹‰æ¨¡å‹æ¥ç†è§£æ•°æ®çš„ä¸šåŠ¡å«ä¹‰ï¼š
- **name**: è¯­ä¹‰å±‚ä¸­çš„å­—æ®µåç§°
- **description**: å­—æ®µçš„ä¸šåŠ¡å«ä¹‰æè¿°
- **expr**: å­—æ®µå¯¹åº”çš„ SQL è¡¨è¾¾å¼
- **synonyms**: åŒä¹‰è¯ï¼Œç”¨æˆ·å¯èƒ½ç”¨è¿™äº›è¯æ¥æŒ‡ä»£è¯¥å­—æ®µ
- **sample_values**: ç¤ºä¾‹å€¼
- **data_type**: æ•°æ®ç±»å‹
"""


# ===============================
# æ•°æ®åº“æ“ä½œå‡½æ•°
# ===============================
@st.cache_data(ttl=300)
def fetch_databases(_conn) -> List[str]:
    """è·å–å¯ç”¨æ•°æ®åº“åˆ—è¡¨"""
    cursor = _conn.cursor()
    cursor.execute("SHOW DATABASES")
    return [row[1] for row in cursor.fetchall()]

@st.cache_data(ttl=300)
def fetch_schemas(_conn, database: str) -> List[str]:
    """è·å–æŒ‡å®šæ•°æ®åº“çš„ Schema åˆ—è¡¨"""
    cursor = _conn.cursor()
    cursor.execute(f"SHOW SCHEMAS IN DATABASE {database}")
    return [f"{database}.{row[1]}" for row in cursor.fetchall()]

@st.cache_data(ttl=300)
def fetch_tables(_conn, schema: str) -> List[str]:
    """è·å–æŒ‡å®š Schema çš„è¡¨åˆ—è¡¨"""
    cursor = _conn.cursor()
    cursor.execute(f"SHOW TABLES IN {schema}")
    tables = [f"{schema}.{row[1]}" for row in cursor.fetchall()]
    cursor.execute(f"SHOW VIEWS IN {schema}")
    views = [f"{schema}.{row[1]}" for row in cursor.fetchall()]
    return tables + views

@st.cache_data(ttl=300)
def fetch_stages(_conn, schema: str) -> List[str]:
    """è·å–æŒ‡å®š Schema çš„ Stage åˆ—è¡¨"""
    cursor = _conn.cursor()
    cursor.execute(f"SHOW STAGES IN {schema}")
    return [f"{schema}.{row[1]}" for row in cursor.fetchall()]

def execute_sql(conn, sql: str) -> Dict[str, Any]:
    """æ‰§è¡Œ SQL æŸ¥è¯¢"""
    try:
        cursor = conn.cursor()
        cursor.execute(sql)
        columns = [desc[0] for desc in cursor.description]
        rows = cursor.fetchall()
        df = pd.DataFrame(rows, columns=columns)
        return {
            "success": True,
            "data": df,
            "row_count": len(df),
            "columns": columns
        }
    except Exception as e:
        return {"success": False, "error": str(e)}

def get_table_info(conn, table_name: str) -> Dict[str, Any]:
    """è·å–è¡¨ç»“æ„ä¿¡æ¯"""
    try:
        cursor = conn.cursor()
        cursor.execute(f"DESC TABLE {table_name}")
        columns = cursor.fetchall()
        schema_info = [{"name": col[0], "type": col[1], "nullable": col[3]} for col in columns]
        
        cursor.execute(f"SELECT COUNT(*) FROM {table_name}")
        row_count = cursor.fetchone()[0]
        
        return {
            "success": True,
            "table_name": table_name,
            "columns": schema_info,
            "row_count": row_count
        }
    except Exception as e:
        return {"success": False, "error": str(e)}


# ===============================
# Agent æ ¸å¿ƒé€»è¾‘ (æ”¯æŒè¯­ä¹‰æ¨¡å‹)
# ===============================
AGENT_SYSTEM_PROMPT_WITH_SEMANTIC = """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ•°æ®åˆ†æåŠ©æ‰‹ï¼Œè¿è¡Œåœ¨ Snowflake ç¯å¢ƒä¸­ã€‚

## é‡è¦ï¼šè¯­ä¹‰æ¨¡å‹

ä½ å¿…é¡»å‚è€ƒä»¥ä¸‹è¯­ä¹‰æ¨¡å‹æ¥ç†è§£æ•°æ®çš„ä¸šåŠ¡å«ä¹‰ã€‚è¯­ä¹‰æ¨¡å‹å®šä¹‰äº†ï¼š
- å­—æ®µçš„ä¸šåŠ¡åç§°å’Œæè¿°
- è®¡ç®—æŒ‡æ ‡çš„å…¬å¼
- å­—æ®µçš„åŒä¹‰è¯ï¼ˆç”¨æˆ·å¯èƒ½ç”¨ä¸åŒçš„è¯æè¿°åŒä¸€ä¸ªå­—æ®µï¼‰
- è¡¨ä¹‹é—´çš„å…³ç³»

{semantic_model}

## å¯ç”¨å·¥å…·:

1. **execute_sql** - æ‰§è¡Œ SQL æŸ¥è¯¢
   å‚æ•°: sql (string) - SQL æŸ¥è¯¢è¯­å¥

2. **get_table_info** - è·å–è¡¨ä¿¡æ¯
   å‚æ•°: table_name (string) - å®Œå…¨é™å®šçš„è¡¨å

## å“åº”æ ¼å¼:

å½“éœ€è¦è°ƒç”¨å·¥å…·æ—¶ï¼Œè¯·ä½¿ç”¨ä»¥ä¸‹ JSON æ ¼å¼ï¼š
```json
{{
  "thought": "ä½ çš„æ€è€ƒè¿‡ç¨‹ï¼ŒåŒ…æ‹¬å¦‚ä½•æ ¹æ®è¯­ä¹‰æ¨¡å‹ç†è§£ç”¨æˆ·æ„å›¾",
  "tool_call": {{
    "name": "å·¥å…·åç§°",
    "parameters": {{
      "å‚æ•°å": "å‚æ•°å€¼"
    }}
  }}
}}
```

å½“ä¸éœ€è¦è°ƒç”¨å·¥å…·ï¼Œç›´æ¥å›ç­”æ—¶ï¼š
```json
{{
  "thought": "ä½ çš„æ€è€ƒè¿‡ç¨‹",
  "response": "ä½ çš„å›ç­”å†…å®¹"
}}
```

## é‡è¦è§„åˆ™:

1. **å¿…é¡»å‚è€ƒè¯­ä¹‰æ¨¡å‹**ï¼šæ ¹æ®è¯­ä¹‰æ¨¡å‹ä¸­çš„ description å’Œ synonyms æ¥ç†è§£ç”¨æˆ·é—®é¢˜
2. **ä½¿ç”¨æ­£ç¡®çš„è¡¨è¾¾å¼**ï¼šä½¿ç”¨è¯­ä¹‰æ¨¡å‹ä¸­å®šä¹‰çš„ expr ä½œä¸º SQL å­—æ®µè¡¨è¾¾å¼
3. **ç†è§£ä¸šåŠ¡æœ¯è¯­**ï¼šç”¨æˆ·å¯èƒ½ä½¿ç”¨ä¸šåŠ¡æœ¯è¯­è€Œéå­—æ®µåï¼Œéœ€è¦æ˜ å°„åˆ°æ­£ç¡®çš„å­—æ®µ
4. SQL æŸ¥è¯¢å¿…é¡»æ˜¯æœ‰æ•ˆçš„ Snowflake SQL è¯­æ³•
5. ä½¿ç”¨ä¸­æ–‡å›ç­”

å½“å‰ä¸Šä¸‹æ–‡:
- æ•°æ®åº“: {database}
- Schema: {schema}
"""

AGENT_SYSTEM_PROMPT_WITHOUT_SEMANTIC = """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ•°æ®åˆ†æåŠ©æ‰‹ï¼Œè¿è¡Œåœ¨ Snowflake ç¯å¢ƒä¸­ã€‚

## å¯ç”¨å·¥å…·:

1. **execute_sql** - æ‰§è¡Œ SQL æŸ¥è¯¢
   å‚æ•°: sql (string) - SQL æŸ¥è¯¢è¯­å¥

2. **get_table_info** - è·å–è¡¨ä¿¡æ¯
   å‚æ•°: table_name (string) - å®Œå…¨é™å®šçš„è¡¨å

## å“åº”æ ¼å¼:

å½“éœ€è¦è°ƒç”¨å·¥å…·æ—¶ï¼š
```json
{{
  "thought": "ä½ çš„æ€è€ƒè¿‡ç¨‹",
  "tool_call": {{
    "name": "å·¥å…·åç§°",
    "parameters": {{"å‚æ•°å": "å‚æ•°å€¼"}}
  }}
}}
```

å½“ç›´æ¥å›ç­”æ—¶ï¼š
```json
{{
  "thought": "ä½ çš„æ€è€ƒè¿‡ç¨‹",
  "response": "ä½ çš„å›ç­”å†…å®¹"
}}
```

è¯·ç”¨ä¸­æ–‡å›ç­”ã€‚

å½“å‰ä¸Šä¸‹æ–‡:
- æ•°æ®åº“: {database}
- Schema: {schema}
- å¯ç”¨è¡¨: {tables}
"""


def parse_agent_response(response: str) -> Dict[str, Any]:
    """è§£æ Agent çš„å“åº”"""
    import re
    try:
        json_match = re.search(r'```json\s*(.*?)\s*```', response, re.DOTALL)
        if json_match:
            return json.loads(json_match.group(1))
        
        start = response.find('{')
        end = response.rfind('}') + 1
        if start != -1 and end > start:
            return json.loads(response[start:end])
    except json.JSONDecodeError:
        pass
    
    return {"response": response}


def run_agent(conn, user_input: str, context: Dict) -> Dict[str, Any]:
    """è¿è¡Œ Agent"""
    semantic_model = context.get("semantic_model")
    
    if semantic_model:
        # ä½¿ç”¨è¯­ä¹‰æ¨¡å‹å¢å¼ºçš„æç¤º
        formatted_model = format_semantic_model_for_prompt(semantic_model)
        system_prompt = AGENT_SYSTEM_PROMPT_WITH_SEMANTIC.format(
            semantic_model=formatted_model,
            database=context.get("database", "æœªé€‰æ‹©"),
            schema=context.get("schema", "æœªé€‰æ‹©")
        )
    else:
        # æ— è¯­ä¹‰æ¨¡å‹çš„åŸºç¡€æç¤º
        system_prompt = AGENT_SYSTEM_PROMPT_WITHOUT_SEMANTIC.format(
            database=context.get("database", "æœªé€‰æ‹©"),
            schema=context.get("schema", "æœªé€‰æ‹©"),
            tables=", ".join(context.get("tables", [])[:10])
        )
    
    messages = context.get("messages", [])
    history_text = ""
    for msg in messages[-6:]:
        role = "ç”¨æˆ·" if msg["role"] == "user" else "åŠ©æ‰‹"
        history_text += f"\n{role}: {msg['content']}\n"
    
    full_prompt = f"{history_text}\nç”¨æˆ·: {user_input}"
    
    # ä½¿ç”¨ session state ä¸­é€‰æ‹©çš„æ¨¡å‹
    model = st.session_state.get("selected_model", DEFAULT_MODEL)
    response = call_qwen_udf(conn, model, full_prompt, system_prompt)
    parsed = parse_agent_response(response)
    
    return parsed


def execute_tool_call(conn, tool_name: str, parameters: Dict, context: Dict) -> Dict[str, Any]:
    """æ‰§è¡Œå·¥å…·è°ƒç”¨"""
    if tool_name == "execute_sql":
        return execute_sql(conn, parameters.get("sql", ""))
    elif tool_name == "get_table_info":
        return get_table_info(conn, parameters.get("table_name", ""))
    else:
        return {"success": False, "error": f"æœªçŸ¥å·¥å…·: {tool_name}"}


# ===============================
# Intelligence åŠŸèƒ½ (æ”¯æŒè¯­ä¹‰æ¨¡å‹)
# ===============================
def generate_data_insights(conn, df: pd.DataFrame, context: str = "", semantic_model: str = None) -> str:
    """ä½¿ç”¨ AI ç”Ÿæˆæ•°æ®æ´å¯Ÿ"""
    summary = f"""
æ•°æ®æ¦‚è§ˆ:
- è¡Œæ•°: {len(df)}
- åˆ—æ•°: {len(df.columns)}
- åˆ—å: {', '.join(df.columns.tolist())}

æ•°æ®ç»Ÿè®¡:
{df.describe().to_string() if len(df) > 0 else 'æ— æ•°æ®'}

å‰5è¡Œæ•°æ®ç¤ºä¾‹:
{df.head().to_string() if len(df) > 0 else 'æ— æ•°æ®'}
"""
    
    semantic_context = ""
    if semantic_model:
        semantic_context = f"""
## è¯­ä¹‰æ¨¡å‹å‚è€ƒ
ä»¥ä¸‹è¯­ä¹‰æ¨¡å‹å®šä¹‰äº†æ•°æ®çš„ä¸šåŠ¡å«ä¹‰ï¼Œè¯·æ®æ­¤è§£è¯»æ•°æ®ï¼š
```yaml
{semantic_model[:2000]}  # æˆªå–å‰2000å­—ç¬¦
```
"""
    
    prompt = f"""è¯·åˆ†æä»¥ä¸‹æ•°æ®å¹¶æä¾›ä¸“ä¸šçš„å•†ä¸šæ´å¯Ÿ:

{summary}

{semantic_context}

{f"ç”¨æˆ·æŸ¥è¯¢èƒŒæ™¯: {context}" if context else ""}

è¯·æä¾›:
1. æ•°æ®çš„å…³é”®å‘ç° (3-5ç‚¹)
2. åŸºäºè¯­ä¹‰æ¨¡å‹çš„ä¸šåŠ¡è§£è¯»
3. å»ºè®®çš„åç»­åˆ†ææ–¹å‘

è¯·ç”¨ä¸“ä¸šä½†æ˜“æ‡‚çš„ä¸­æ–‡å›ç­”ã€‚
"""
    
    # ä½¿ç”¨ session state ä¸­é€‰æ‹©çš„æ¨¡å‹
    model = st.session_state.get("selected_model", DEFAULT_MODEL)
    return call_qwen_udf(conn, model, prompt)


def generate_sql_from_question(conn, question: str, schema_info: Dict, tables: List[str], semantic_model: str = None) -> str:
    """æ ¹æ®è‡ªç„¶è¯­è¨€é—®é¢˜ç”Ÿæˆ SQLï¼ˆæ”¯æŒè¯­ä¹‰æ¨¡å‹ï¼‰"""
    
    semantic_context = ""
    if semantic_model:
        semantic_context = f"""
## é‡è¦ï¼šè¯­ä¹‰æ¨¡å‹

è¯·æ ¹æ®ä»¥ä¸‹è¯­ä¹‰æ¨¡å‹æ¥ç†è§£æ•°æ®çš„ä¸šåŠ¡å«ä¹‰ï¼Œå¹¶ç”Ÿæˆæ­£ç¡®çš„ SQLï¼š

```yaml
{semantic_model}
```

è§„åˆ™ï¼š
1. æ ¹æ®è¯­ä¹‰æ¨¡å‹ä¸­çš„ description ç†è§£å­—æ®µå«ä¹‰
2. ä½¿ç”¨è¯­ä¹‰æ¨¡å‹ä¸­çš„ expr ä½œä¸º SQL è¡¨è¾¾å¼
3. å‚è€ƒ synonyms æ¥åŒ¹é…ç”¨æˆ·ä½¿ç”¨çš„ä¸šåŠ¡æœ¯è¯­
4. å¦‚æœç”¨æˆ·é—®çš„æŒ‡æ ‡åœ¨è¯­ä¹‰æ¨¡å‹ä¸­æœ‰å®šä¹‰ï¼Œä½¿ç”¨å®šä¹‰çš„è®¡ç®—å…¬å¼
"""
    
    prompt = f"""è¯·æ ¹æ®ä»¥ä¸‹é—®é¢˜ç”Ÿæˆ Snowflake SQL æŸ¥è¯¢:

é—®é¢˜: {question}

{semantic_context}

å¯ç”¨è¡¨: {', '.join(tables)}

è¡¨ç»“æ„ä¿¡æ¯:
{json.dumps(schema_info, indent=2, ensure_ascii=False)}

è¦æ±‚:
1. ç”Ÿæˆæœ‰æ•ˆçš„ Snowflake SQL
2. åªè¿”å› SQL è¯­å¥ï¼Œä¸è¦ä»»ä½•è§£é‡Š
3. ä½¿ç”¨å®Œå…¨é™å®šçš„è¡¨å
4. æ·»åŠ  LIMIT 100 é™åˆ¶ç»“æœæ•°é‡
5. å¦‚æœæœ‰è¯­ä¹‰æ¨¡å‹ï¼Œå¿…é¡»å‚è€ƒå…¶ä¸­çš„å­—æ®µå®šä¹‰å’Œè¡¨è¾¾å¼

SQL:
"""
    
    # ä½¿ç”¨ session state ä¸­é€‰æ‹©çš„æ¨¡å‹
    model = st.session_state.get("selected_model", DEFAULT_MODEL)
    response = call_qwen_udf(conn, model, prompt)
    
    sql = response.strip()
    if sql.startswith("```"):
        lines = sql.split("\n")
        sql_lines = []
        in_code = False
        for line in lines:
            if line.startswith("```"):
                in_code = not in_code
                continue
            if in_code or not line.startswith("```"):
                sql_lines.append(line)
        sql = "\n".join(sql_lines).strip()
    
    return sql


def suggest_questions(conn, tables: List[str], schema_info: Dict, semantic_model: str = None) -> List[str]:
    """æ ¹æ®è¡¨ç»“æ„å’Œè¯­ä¹‰æ¨¡å‹å»ºè®®é—®é¢˜"""
    
    semantic_context = ""
    if semantic_model:
        semantic_context = f"""
è¯­ä¹‰æ¨¡å‹ï¼ˆåŒ…å«ä¸šåŠ¡å®šä¹‰ï¼‰ï¼š
```yaml
{semantic_model[:1500]}
```

è¯·æ ¹æ®è¯­ä¹‰æ¨¡å‹ä¸­å®šä¹‰çš„æŒ‡æ ‡å’Œç»´åº¦æ¥å»ºè®®é—®é¢˜ã€‚
"""
    
    prompt = f"""åŸºäºä»¥ä¸‹æ•°æ®ä¿¡æ¯ï¼Œå»ºè®®5ä¸ªæœ‰ä»·å€¼çš„æ•°æ®åˆ†æé—®é¢˜:

å¯ç”¨è¡¨: {', '.join(tables[:5])}

è¡¨ç»“æ„ä¿¡æ¯:
{json.dumps(schema_info, indent=2, ensure_ascii=False)}

{semantic_context}

è¯·ç”Ÿæˆ5ä¸ªå…·ä½“ã€å¯æ‰§è¡Œçš„æ•°æ®åˆ†æé—®é¢˜ï¼Œæ¯è¡Œä¸€ä¸ªé—®é¢˜ã€‚
å¦‚æœæœ‰è¯­ä¹‰æ¨¡å‹ï¼Œè¯·ä½¿ç”¨å…¶ä¸­å®šä¹‰çš„ä¸šåŠ¡æœ¯è¯­æ¥æé—®ã€‚
åªè¾“å‡ºé—®é¢˜ï¼Œä¸è¦ç¼–å·ã€‚
"""
    
    # ä½¿ç”¨å¿«é€Ÿæ¨¡å‹æ¥ç”Ÿæˆå»ºè®®é—®é¢˜
    response = call_qwen_udf(conn, "qwen-turbo", prompt)
    questions = [q.strip() for q in response.strip().split('\n') if q.strip()]
    return questions[:5]


# ===============================
# UI ç»„ä»¶
# ===============================
def render_message(role: str, content: str, tool_info: Dict = None):
    """æ¸²æŸ“èŠå¤©æ¶ˆæ¯"""
    if role == "user":
        st.markdown(f'<div class="user-message">{content}</div>', unsafe_allow_html=True)
    else:
        st.markdown(f'<div class="agent-message">{content}</div>', unsafe_allow_html=True)
        if tool_info:
            st.markdown(f"""
            <div class="tool-card">
                ğŸ”§ å·¥å…·è°ƒç”¨: <strong>{tool_info.get('name', 'unknown')}</strong><br>
                å‚æ•°: {json.dumps(tool_info.get('parameters', {}), ensure_ascii=False)}
            </div>
            """, unsafe_allow_html=True)


def render_data_preview(df: pd.DataFrame, title: str = "æ•°æ®é¢„è§ˆ"):
    """æ¸²æŸ“æ•°æ®é¢„è§ˆ"""
    st.markdown(f"### ğŸ“Š {title}")
    st.dataframe(
        df,
        use_container_width=True,
        hide_index=True,
        height=min(400, 35 * len(df) + 38)
    )


# ===============================
# ä¸»åº”ç”¨
# ===============================
def main():
    # æ³¨å…¥è‡ªå®šä¹‰æ ·å¼
    st.markdown(CUSTOM_CSS, unsafe_allow_html=True)
    
    # è·å–æ—¶é—´é—®å€™è¯­
    greeting_en, greeting_cn = get_time_greeting("Yuheng")
    
    # æ ‡é¢˜å’Œé—®å€™è¯­
    st.markdown(f'<h1 class="main-title">â„ï¸ Intelligence</h1>', unsafe_allow_html=True)
    st.markdown(f'<h2 style="text-align: center; color: #E8E8E8; font-weight: 400; margin-bottom: 0.5rem;">{greeting_en}</h2>', unsafe_allow_html=True)
    st.markdown('<p class="subtitle" style="background: linear-gradient(135deg, #00D4FF 0%, #7B2CBF 100%); -webkit-background-clip: text; -webkit-text-fill-color: transparent; background-clip: text; font-size: 1.5rem; font-weight: 500;">What insights can I help with?</p>', unsafe_allow_html=True)
    
    # åˆå§‹åŒ– session state
    if "agent_messages" not in st.session_state:
        st.session_state.agent_messages = []
    
    if "last_query_result" not in st.session_state:
        st.session_state.last_query_result = None
    
    if "selected_database" not in st.session_state:
        st.session_state.selected_database = None
    
    if "selected_schema" not in st.session_state:
        st.session_state.selected_schema = None
    
    if "available_tables" not in st.session_state:
        st.session_state.available_tables = []
    
    if "semantic_model" not in st.session_state:
        st.session_state.semantic_model = None
    
    if "semantic_model_name" not in st.session_state:
        st.session_state.semantic_model_name = None
    
    if "selected_provider" not in st.session_state:
        st.session_state.selected_provider = DEFAULT_PROVIDER
    
    if "selected_model" not in st.session_state:
        st.session_state.selected_model = DEFAULT_MODEL
    
    # è·å–è¿æ¥
    try:
        conn = get_snowflake_connection()
    except Exception as e:
        st.error(f"æ— æ³•è¿æ¥åˆ° Snowflake: {e}")
        return
    
    # ä¾§è¾¹æ  - æ•°æ®æºå’Œè¯­ä¹‰æ¨¡å‹é€‰æ‹©
    with st.sidebar:
        st.markdown("### ğŸ§  æ¨¡å‹é€‰æ‹©")
        
        # æ¨¡å‹æä¾›å•†é€‰æ‹©
        provider_list = list(MODEL_PROVIDERS.keys())
        selected_provider = st.selectbox(
            "é€‰æ‹©æ¨¡å‹æä¾›å•†",
            options=provider_list,
            index=provider_list.index(st.session_state.selected_provider) if st.session_state.selected_provider in provider_list else 0,
            key="provider_selector"
        )
        
        # å¦‚æœæä¾›å•†å˜åŒ–ï¼Œæ›´æ–°é»˜è®¤æ¨¡å‹
        if selected_provider != st.session_state.selected_provider:
            st.session_state.selected_provider = selected_provider
            st.session_state.selected_model = MODEL_PROVIDERS[selected_provider]["default"]
        
        # å­æ¨¡å‹é€‰æ‹©
        provider_models = MODEL_PROVIDERS[selected_provider]["models"]
        model_list = list(provider_models.keys())
        
        # ç¡®ä¿å½“å‰é€‰ä¸­çš„æ¨¡å‹åœ¨åˆ—è¡¨ä¸­
        current_model_index = 0
        if st.session_state.selected_model in model_list:
            current_model_index = model_list.index(st.session_state.selected_model)
        
        selected_model = st.selectbox(
            "é€‰æ‹©æ¨¡å‹",
            options=model_list,
            index=current_model_index,
            format_func=lambda x: provider_models[x],
            key="model_selector"
        )
        
        if selected_model != st.session_state.selected_model:
            st.session_state.selected_model = selected_model
        
        st.caption(f"ğŸ“ **{selected_provider}** / `{selected_model}`")
        
        st.markdown("---")
        st.markdown("### ğŸ—„ï¸ æ•°æ®æºé…ç½®")
        
        # æ•°æ®åº“é€‰æ‹©
        try:
            databases = fetch_databases(conn)
        except Exception:
            databases = []
        
        selected_db = st.selectbox(
            "é€‰æ‹©æ•°æ®åº“",
            options=databases,
            index=0 if databases else None,
            key="db_selector"
        )
        
        if selected_db != st.session_state.selected_database:
            st.session_state.selected_database = selected_db
            st.session_state.selected_schema = None
            st.session_state.available_tables = []
            st.session_state.semantic_model = None
        
        # Schema é€‰æ‹©
        if selected_db:
            try:
                schemas = fetch_schemas(conn, selected_db)
                selected_schema = st.selectbox(
                    "é€‰æ‹© Schema",
                    options=schemas,
                    index=0 if schemas else None,
                    key="schema_selector",
                    format_func=lambda x: x.split(".")[-1] if "." in x else x
                )
                
                if selected_schema != st.session_state.selected_schema:
                    st.session_state.selected_schema = selected_schema
                    try:
                        st.session_state.available_tables = fetch_tables(conn, selected_schema)
                    except Exception:
                        st.session_state.available_tables = []
            except Exception:
                st.warning("æ— æ³•è·å– Schema åˆ—è¡¨")
        
        # ===== è¯­ä¹‰æ¨¡å‹é…ç½® =====
        st.markdown("---")
        st.markdown("### ğŸ“š è¯­ä¹‰æ¨¡å‹")
        
        if st.session_state.semantic_model:
            st.success(f"âœ… å·²åŠ è½½: {st.session_state.semantic_model_name}")
            if st.button("ğŸ—‘ï¸ å¸è½½è¯­ä¹‰æ¨¡å‹"):
                st.session_state.semantic_model = None
                st.session_state.semantic_model_name = None
                st.experimental_rerun()
        else:
            st.info("ğŸ’¡ åŠ è½½è¯­ä¹‰æ¨¡å‹å¯æå‡ SQL ç”Ÿæˆå‡†ç¡®æ€§")
        
        # ä» Stage åŠ è½½è¯­ä¹‰æ¨¡å‹
        if st.session_state.selected_schema:
            try:
                stages = fetch_stages(conn, st.session_state.selected_schema)
                if stages:
                    selected_stage = st.selectbox(
                        "é€‰æ‹© Stage",
                        options=stages,
                        format_func=lambda x: x.split(".")[-1],
                        key="stage_selector"
                    )
                    
                    if selected_stage:
                        yaml_files = list_yaml_files_in_stage(conn, selected_stage)
                        if yaml_files:
                            selected_yaml = st.selectbox(
                                "é€‰æ‹©è¯­ä¹‰æ¨¡å‹æ–‡ä»¶",
                                options=yaml_files,
                                format_func=lambda x: x.split("/")[-1],
                                key="yaml_selector"
                            )
                            
                            if st.button("ğŸ“¥ åŠ è½½è¯­ä¹‰æ¨¡å‹", type="primary"):
                                with st.spinner("åŠ è½½ä¸­..."):
                                    yaml_content = load_semantic_model_from_stage(conn, f"@{selected_stage}/{selected_yaml.split('/')[-1]}")
                                    if yaml_content:
                                        st.session_state.semantic_model = yaml_content
                                        st.session_state.semantic_model_name = selected_yaml.split("/")[-1]
                                        st.success("âœ… è¯­ä¹‰æ¨¡å‹åŠ è½½æˆåŠŸï¼")
                                        st.experimental_rerun()
                        else:
                            st.caption("è¯¥ Stage ä¸­æ²¡æœ‰ YAML æ–‡ä»¶")
            except Exception as e:
                st.caption(f"æ— æ³•åˆ—å‡º Stage: {e}")
        
        # æ‰‹åŠ¨è¾“å…¥è¯­ä¹‰æ¨¡å‹
        with st.expander("ğŸ“ æ‰‹åŠ¨è¾“å…¥è¯­ä¹‰æ¨¡å‹"):
            manual_yaml = st.text_area(
                "ç²˜è´´è¯­ä¹‰æ¨¡å‹ YAML",
                height=200,
                placeholder="ç²˜è´´æ‚¨çš„è¯­ä¹‰æ¨¡å‹ YAML å†…å®¹..."
            )
            if st.button("åº”ç”¨è¯­ä¹‰æ¨¡å‹"):
                if manual_yaml.strip():
                    st.session_state.semantic_model = manual_yaml
                    st.session_state.semantic_model_name = "æ‰‹åŠ¨è¾“å…¥"
                    st.success("âœ… è¯­ä¹‰æ¨¡å‹å·²åº”ç”¨ï¼")
                    st.experimental_rerun()
        
        # æ˜¾ç¤ºå¯ç”¨è¡¨
        st.markdown("---")
        if st.session_state.available_tables:
            st.markdown("### ğŸ“‹ å¯ç”¨æ•°æ®è¡¨")
            for table in st.session_state.available_tables[:10]:
                table_name = table.split(".")[-1]
                st.markdown(f"- `{table_name}`")
            if len(st.session_state.available_tables) > 10:
                st.caption(f"... è¿˜æœ‰ {len(st.session_state.available_tables) - 10} å¼ è¡¨")
        
        st.markdown("---")
        
        # æ¸…é™¤å¯¹è¯æŒ‰é’®
        if st.button("ğŸ—‘ï¸ æ¸…é™¤å¯¹è¯", use_container_width=True):
            st.session_state.agent_messages = []
            st.session_state.last_query_result = None
            st.experimental_rerun()
    
    # ä¸»è¦å†…å®¹åŒº - æ ‡ç­¾é¡µ
    tab1, tab2, tab3 = st.tabs(["ğŸ¤– æ™ºèƒ½å¯¹è¯ (Agent)", "ğŸ“ˆ æ•°æ®æ´å¯Ÿ (Intelligence)", "ğŸ”§ å·¥å…·ç®±"])
    
    # ===== Tab 1: Agent å¯¹è¯ =====
    with tab1:
        # è¯­ä¹‰æ¨¡å‹çŠ¶æ€æç¤º
        if st.session_state.semantic_model:
            st.markdown(f"""
            <div class="feature-card">
                <span class="semantic-badge">ğŸ¯ è¯­ä¹‰æ¨¡å‹å·²å¯ç”¨</span>
                <h3 style="margin-top: 1rem;">ğŸ’¬ ä¸ AI åŠ©æ‰‹å¯¹è¯</h3>
                <p>è¯­ä¹‰æ¨¡å‹ <strong>{st.session_state.semantic_model_name}</strong> å·²åŠ è½½ï¼ŒAI å°†å‚è€ƒä¸šåŠ¡å®šä¹‰æ¥ç†è§£æ‚¨çš„é—®é¢˜ã€‚</p>
            </div>
            """, unsafe_allow_html=True)
        else:
            st.markdown("""
            <div class="feature-card">
                <h3>ğŸ’¬ ä¸ AI åŠ©æ‰‹å¯¹è¯</h3>
                <p>âš ï¸ <strong>æç¤º</strong>ï¼šæœªåŠ è½½è¯­ä¹‰æ¨¡å‹ï¼ŒSQL ç”Ÿæˆä»…åŸºäºè¡¨ç»“æ„ã€‚å»ºè®®åœ¨ä¾§è¾¹æ åŠ è½½è¯­ä¹‰æ¨¡å‹ä»¥è·å¾—æ›´å¥½çš„æ•ˆæœã€‚</p>
            </div>
            """, unsafe_allow_html=True)
        
        # å¯¹è¯å†å²
        chat_container = st.container()
        with chat_container:
            for msg in st.session_state.agent_messages:
                render_message(
                    msg["role"], 
                    msg["content"],
                    msg.get("tool_info")
                )
                if msg.get("data") is not None:
                    render_data_preview(msg["data"], "æŸ¥è¯¢ç»“æœ")
        
        # è¾“å…¥æ¡† (ä½¿ç”¨ text_input æ›¿ä»£ chat_input ä»¥å…¼å®¹ SiS)
        def submit_question():
            if st.session_state.user_question_input:
                st.session_state.submitted_question = st.session_state.user_question_input
                st.session_state.user_question_input = ""
        
        col_input, col_btn = st.columns([5, 1])
        with col_input:
            st.text_input(
                "è¾“å…¥ä½ çš„é—®é¢˜",
                key="user_question_input",
                placeholder="Ask Snowflake Intelligence...",
                label_visibility="collapsed",
                on_change=submit_question
            )
        with col_btn:
            if st.button("å‘é€", type="primary", use_container_width=True):
                submit_question()
        
        # å¤„ç†æäº¤çš„é—®é¢˜
        user_input = st.session_state.pop("submitted_question", None)
        
        if user_input:
            # æ·»åŠ ç”¨æˆ·æ¶ˆæ¯
            st.session_state.agent_messages.append({
                "role": "user",
                "content": user_input
            })
            
            # å‡†å¤‡ä¸Šä¸‹æ–‡
            context = {
                "database": st.session_state.selected_database,
                "schema": st.session_state.selected_schema,
                "tables": st.session_state.available_tables,
                "messages": st.session_state.agent_messages,
                "last_query_result": st.session_state.last_query_result,
                "semantic_model": st.session_state.semantic_model  # ä¼ å…¥è¯­ä¹‰æ¨¡å‹
            }
            
            # è¿è¡Œ Agent
            with st.spinner("ğŸ¤” æ€è€ƒä¸­ï¼ˆå‚è€ƒè¯­ä¹‰æ¨¡å‹ï¼‰..." if st.session_state.semantic_model else "ğŸ¤” æ€è€ƒä¸­..."):
                response = run_agent(conn, user_input, context)
            
            # å¤„ç†å“åº”
            thought = response.get("thought", "")
            tool_call = response.get("tool_call")
            direct_response = response.get("response")
            
            agent_message = {
                "role": "assistant",
                "content": "",
                "tool_info": None,
                "data": None
            }
            
            if tool_call:
                tool_name = tool_call.get("name")
                parameters = tool_call.get("parameters", {})
                
                agent_message["tool_info"] = {"name": tool_name, "parameters": parameters}
                
                with st.spinner(f"ğŸ”§ æ‰§è¡Œ {tool_name}..."):
                    result = execute_tool_call(conn, tool_name, parameters, context)
                
                if result.get("success"):
                    if "data" in result:
                        agent_message["data"] = result["data"]
                        st.session_state.last_query_result = result["data"]
                        agent_message["content"] = f"{thought}\n\nâœ… æŸ¥è¯¢æˆåŠŸï¼Œè¿”å› {result['row_count']} è¡Œæ•°æ®ã€‚"
                    elif "columns" in result:
                        cols_info = "\n".join([f"- {c['name']}: {c['type']}" for c in result['columns']])
                        agent_message["content"] = f"{thought}\n\nğŸ“‹ è¡¨ `{result['table_name']}` ç»“æ„ (å…± {result['row_count']} è¡Œ):\n{cols_info}"
                    else:
                        agent_message["content"] = f"{thought}\n\nâœ… æ‰§è¡ŒæˆåŠŸã€‚"
                else:
                    agent_message["content"] = f"{thought}\n\nâŒ æ‰§è¡Œå¤±è´¥: {result.get('error', 'æœªçŸ¥é”™è¯¯')}"
            
            elif direct_response:
                agent_message["content"] = direct_response
            else:
                agent_message["content"] = str(response)
            
            st.session_state.agent_messages.append(agent_message)
            st.experimental_rerun()
    
    # ===== Tab 2: Intelligence =====
    with tab2:
        if st.session_state.semantic_model:
            st.markdown(f"""
            <div class="feature-card">
                <span class="semantic-badge">ğŸ¯ è¯­ä¹‰æ¨¡å‹å·²å¯ç”¨</span>
                <h3 style="margin-top: 1rem;">ğŸ“Š æ™ºèƒ½æ•°æ®æ´å¯Ÿ</h3>
                <p>ä½¿ç”¨è¯­ä¹‰æ¨¡å‹ <strong>{st.session_state.semantic_model_name}</strong> æ¥ç†è§£æ‚¨çš„ä¸šåŠ¡é—®é¢˜ã€‚</p>
            </div>
            """, unsafe_allow_html=True)
        else:
            st.markdown("""
            <div class="feature-card">
                <h3>ğŸ“Š æ™ºèƒ½æ•°æ®æ´å¯Ÿ</h3>
                <p>ç”¨è‡ªç„¶è¯­è¨€æè¿°ä½ æƒ³æŸ¥è¯¢çš„å†…å®¹ã€‚âš ï¸ å»ºè®®å…ˆåŠ è½½è¯­ä¹‰æ¨¡å‹ä»¥è·å¾—æ›´å‡†ç¡®çš„ç»“æœã€‚</p>
            </div>
            """, unsafe_allow_html=True)
        
        col1, col2 = st.columns([2, 1])
        
        with col1:
            st.markdown("### ğŸ” è‡ªç„¶è¯­è¨€æŸ¥è¯¢")
            nl_query = st.text_area(
                "ç”¨è‡ªç„¶è¯­è¨€æè¿°ä½ æƒ³æŸ¥è¯¢çš„å†…å®¹",
                placeholder="ä¾‹å¦‚ï¼šæŸ¥è¯¢è¿‡å»ä¸€ä¸ªæœˆæ¯å¤©çš„è®¢å•æ•°é‡å’Œæ€»é‡‘é¢\n\nå¦‚æœæœ‰è¯­ä¹‰æ¨¡å‹ï¼Œå¯ä»¥ä½¿ç”¨ä¸šåŠ¡æœ¯è¯­å¦‚ï¼šVIPå®¢æˆ·ã€é”€å”®é¢ã€é€€è´§ç‡ç­‰",
                height=100
            )
            
            if st.button("ğŸš€ ç”Ÿæˆå¹¶æ‰§è¡ŒæŸ¥è¯¢", type="primary"):
                if nl_query and st.session_state.available_tables:
                    # è·å–è¡¨ç»“æ„ä¿¡æ¯
                    schema_info = {}
                    for table in st.session_state.available_tables[:5]:
                        try:
                            result = get_table_info(conn, table)
                            if result["success"]:
                                schema_info[table] = result["columns"]
                        except Exception:
                            pass
                    
                    with st.spinner("ğŸ§  ç”Ÿæˆ SQLï¼ˆå‚è€ƒè¯­ä¹‰æ¨¡å‹ï¼‰..." if st.session_state.semantic_model else "ğŸ§  ç”Ÿæˆ SQL..."):
                        sql = generate_sql_from_question(
                            conn, nl_query, schema_info, 
                            st.session_state.available_tables,
                            st.session_state.semantic_model  # ä¼ å…¥è¯­ä¹‰æ¨¡å‹
                        )
                    
                    st.markdown("**ç”Ÿæˆçš„ SQL:**")
                    st.code(sql, language="sql")
                    
                    # æ‰§è¡ŒæŸ¥è¯¢
                    with st.spinner("âš¡ æ‰§è¡ŒæŸ¥è¯¢..."):
                        result = execute_sql(conn, sql)
                    
                    if result["success"]:
                        st.session_state.last_query_result = result["data"]
                        render_data_preview(result["data"])
                        
                        # ç”Ÿæˆæ´å¯Ÿ
                        with st.spinner("ğŸ’¡ ç”Ÿæˆæ•°æ®æ´å¯Ÿ..."):
                            insights = generate_data_insights(
                                conn, result["data"], nl_query,
                                st.session_state.semantic_model  # ä¼ å…¥è¯­ä¹‰æ¨¡å‹
                            )
                        
                        st.markdown("### ğŸ’¡ AI æ´å¯Ÿ")
                        st.markdown(insights)
                    else:
                        st.error(f"æŸ¥è¯¢å¤±è´¥: {result['error']}")
                else:
                    st.warning("è¯·å…ˆé€‰æ‹©æ•°æ®æºå¹¶è¾“å…¥æŸ¥è¯¢å†…å®¹")
        
        with col2:
            st.markdown("### ğŸ’¡ å»ºè®®çš„é—®é¢˜")
            if st.session_state.available_tables and st.button("ç”Ÿæˆå»ºè®®"):
                schema_info = {}
                for table in st.session_state.available_tables[:3]:
                    try:
                        result = get_table_info(conn, table)
                        if result["success"]:
                            schema_info[table] = result["columns"]
                    except Exception:
                        pass
                
                with st.spinner("ç”Ÿæˆå»ºè®®é—®é¢˜..."):
                    questions = suggest_questions(
                        conn, st.session_state.available_tables, schema_info,
                        st.session_state.semantic_model  # ä¼ å…¥è¯­ä¹‰æ¨¡å‹
                    )
                
                for q in questions:
                    st.info(f"ğŸ“Œ {q}")
    
    # ===== Tab 3: å·¥å…·ç®± =====
    with tab3:
        st.markdown("""
        <div class="feature-card">
            <h3>ğŸ”§ æ•°æ®å·¥å…·ç®±</h3>
            <p>ç›´æ¥ä½¿ç”¨ SQL æŸ¥è¯¢å’Œè¡¨ä¿¡æ¯æŸ¥è¯¢å·¥å…·ã€‚</p>
        </div>
        """, unsafe_allow_html=True)
        
        tool_tabs = st.tabs(["SQL æŸ¥è¯¢", "è¡¨ä¿¡æ¯", "æ•°æ®ç»Ÿè®¡", "è¯­ä¹‰æ¨¡å‹é¢„è§ˆ"])
        
        # SQL æŸ¥è¯¢å·¥å…·
        with tool_tabs[0]:
            st.markdown("### ğŸ“ SQL æŸ¥è¯¢")
            sql_input = st.text_area(
                "è¾“å…¥ SQL æŸ¥è¯¢",
                height=150,
                placeholder="SELECT * FROM your_table LIMIT 10"
            )
            
            if st.button("â–¶ï¸ æ‰§è¡ŒæŸ¥è¯¢", key="run_sql"):
                if sql_input:
                    with st.spinner("æ‰§è¡Œä¸­..."):
                        result = execute_sql(conn, sql_input)
                    
                    if result["success"]:
                        st.success(f"æŸ¥è¯¢æˆåŠŸï¼Œè¿”å› {result['row_count']} è¡Œ")
                        st.session_state.last_query_result = result["data"]
                        render_data_preview(result["data"])
                    else:
                        st.error(f"æŸ¥è¯¢å¤±è´¥: {result['error']}")
        
        # è¡¨ä¿¡æ¯å·¥å…·
        with tool_tabs[1]:
            st.markdown("### ğŸ“‹ è¡¨ç»“æ„æŸ¥è¯¢")
            if st.session_state.available_tables:
                selected_table = st.selectbox(
                    "é€‰æ‹©è¡¨",
                    st.session_state.available_tables,
                    format_func=lambda x: x.split(".")[-1]
                )
                
                if st.button("ğŸ” æŸ¥çœ‹ç»“æ„", key="view_schema"):
                    with st.spinner("è·å–è¡¨ä¿¡æ¯..."):
                        result = get_table_info(conn, selected_table)
                    
                    if result["success"]:
                        st.markdown(f"**è¡¨å:** `{result['table_name']}`")
                        st.markdown(f"**è¡Œæ•°:** {result['row_count']:,}")
                        
                        cols_df = pd.DataFrame(result["columns"])
                        st.dataframe(cols_df, use_container_width=True, hide_index=True)
                    else:
                        st.error(result["error"])
            else:
                st.info("è¯·å…ˆåœ¨ä¾§è¾¹æ é€‰æ‹©æ•°æ®åº“å’Œ Schema")
        
        # æ•°æ®ç»Ÿè®¡å·¥å…·
        with tool_tabs[2]:
            st.markdown("### ğŸ“Š æ•°æ®ç»Ÿè®¡")
            if st.session_state.last_query_result is not None:
                df = st.session_state.last_query_result
                
                st.markdown(f"**æ•°æ®ç»´åº¦:** {len(df)} è¡Œ Ã— {len(df.columns)} åˆ—")
                
                st.markdown("**æè¿°æ€§ç»Ÿè®¡:**")
                st.dataframe(df.describe(), use_container_width=True)
                
                st.markdown("**æ•°æ®ç±»å‹:**")
                dtype_df = pd.DataFrame({
                    "åˆ—å": df.columns,
                    "æ•°æ®ç±»å‹": df.dtypes.astype(str).values,
                    "éç©ºæ•°é‡": df.count().values,
                    "ç©ºå€¼æ•°é‡": df.isnull().sum().values
                })
                st.dataframe(dtype_df, use_container_width=True, hide_index=True)
            else:
                st.info("è¯·å…ˆæ‰§è¡ŒæŸ¥è¯¢ä»¥è·å–æ•°æ®")
        
        # è¯­ä¹‰æ¨¡å‹é¢„è§ˆ
        with tool_tabs[3]:
            st.markdown("### ğŸ“š è¯­ä¹‰æ¨¡å‹é¢„è§ˆ")
            if st.session_state.semantic_model:
                st.markdown(f"**å½“å‰åŠ è½½:** `{st.session_state.semantic_model_name}`")
                st.code(st.session_state.semantic_model, language="yaml")
            else:
                st.info("æœªåŠ è½½è¯­ä¹‰æ¨¡å‹ã€‚è¯·åœ¨ä¾§è¾¹æ åŠ è½½è¯­ä¹‰æ¨¡å‹ã€‚")


if __name__ == "__main__":
    main()
