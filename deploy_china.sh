#!/bin/bash
# ============================================================================
# Semantic Model Generator - China Region Deployment Script
# ä¸­å›½åŒºéƒ¨ç½²è„šæœ¬
# ============================================================================

set -e

echo "=========================================="
echo "Semantic Model Generator - ä¸­å›½åŒºéƒ¨ç½²"
echo "=========================================="

# é…ç½®å˜é‡
SNOW_CONNECTION="china"
QWEN_API_KEY="${QWEN_API_KEY:-sk-974d67fdc0744f1fb0723686c810f327}"

# æ£€æŸ¥ Snow CLI
if ! command -v snow &> /dev/null; then
    echo "âŒ é”™è¯¯: Snowflake CLI æœªå®‰è£…"
    echo "è¯·å‚è€ƒ: https://docs.snowflake.com/en/developer-guide/snowflake-cli-v2/installation/installation"
    exit 1
fi

# æ£€æŸ¥è¿æ¥é…ç½®
echo ""
echo "ğŸ“¡ éªŒè¯ Snowflake ä¸­å›½åŒºè¿æ¥..."
snow connection test --connection $SNOW_CONNECTION || {
    echo "âŒ è¿æ¥æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥ ~/.snowflake/connections.toml ä¸­çš„ [$SNOW_CONNECTION] é…ç½®"
    exit 1
}

echo "âœ… è¿æ¥éªŒè¯æˆåŠŸ"

# åˆ‡æ¢åˆ°é¡¹ç›®ç›®å½•
cd "$(dirname "$0")"

echo ""
echo "ğŸ“¦ Step 1: åˆ›å»ºæ•°æ®åº“ã€Schema å’Œ Qwen UDF..."
echo "-------------------------------------------"

# é¦–å…ˆåˆ›å»ºåŸºç¡€å¯¹è±¡å’Œ Qwen UDF
cat > /tmp/china_qwen_setup.sql << 'EOSQL'
-- åˆ›å»ºæ•°æ®åº“å’Œ Schema
CREATE DATABASE IF NOT EXISTS CORTEX_ANALYST_SEMANTICS;
CREATE SCHEMA IF NOT EXISTS CORTEX_ANALYST_SEMANTICS.SEMANTIC_MODEL_GENERATOR;
USE DATABASE CORTEX_ANALYST_SEMANTICS;
USE SCHEMA SEMANTIC_MODEL_GENERATOR;

-- åˆ›å»ºç½‘ç»œè§„åˆ™å…è®¸è®¿é—®é€šä¹‰åƒé—® API
CREATE OR REPLACE NETWORK RULE qwen_api_network_rule
    MODE = EGRESS
    TYPE = HOST_PORT
    VALUE_LIST = ('dashscope.aliyuncs.com:443');
EOSQL

snow sql -f /tmp/china_qwen_setup.sql --connection $SNOW_CONNECTION

# åˆ›å»º Secret (å¸¦ API Key)
echo ""
echo "ğŸ” Step 2: åˆ›å»º Qwen API Secret..."
snow sql -q "CREATE OR REPLACE SECRET CORTEX_ANALYST_SEMANTICS.SEMANTIC_MODEL_GENERATOR.qwen_api_secret TYPE = GENERIC_STRING SECRET_STRING = '$QWEN_API_KEY';" --connection $SNOW_CONNECTION

# åˆ›å»ºå¤–éƒ¨è®¿é—®é›†æˆ
echo ""
echo "ğŸŒ Step 3: åˆ›å»º External Access Integration..."
cat > /tmp/china_integration.sql << 'EOSQL'
USE DATABASE CORTEX_ANALYST_SEMANTICS;
USE SCHEMA SEMANTIC_MODEL_GENERATOR;

CREATE OR REPLACE EXTERNAL ACCESS INTEGRATION qwen_api_integration
    ALLOWED_NETWORK_RULES = (qwen_api_network_rule)
    ALLOWED_AUTHENTICATION_SECRETS = (qwen_api_secret)
    ENABLED = TRUE;
EOSQL

snow sql -f /tmp/china_integration.sql --connection $SNOW_CONNECTION

# åˆ›å»º Qwen UDF
echo ""
echo "ğŸ¤– Step 4: åˆ›å»º Qwen Complete UDF..."
cat > /tmp/china_qwen_udf.sql << 'EOSQL'
USE DATABASE CORTEX_ANALYST_SEMANTICS;
USE SCHEMA SEMANTIC_MODEL_GENERATOR;

CREATE OR REPLACE FUNCTION QWEN_COMPLETE(model VARCHAR, prompt VARCHAR)
RETURNS VARCHAR
LANGUAGE PYTHON
RUNTIME_VERSION = '3.10'
PACKAGES = ('requests')
HANDLER = 'qwen_complete'
EXTERNAL_ACCESS_INTEGRATIONS = (qwen_api_integration)
SECRETS = ('api_key' = qwen_api_secret)
AS $$
import requests
import json
import _snowflake

def qwen_complete(model: str, prompt: str) -> str:
    api_key = _snowflake.get_generic_secret_string('api_key')
    
    model_mapping = {
        'llama3-8b': 'qwen-turbo',
        'mistral-large2': 'qwen-max',
        'mixtral-8x7b': 'qwen-plus',
    }
    qwen_model = model_mapping.get(model.lower(), model)
    
    headers = {
        "Authorization": f"Bearer {api_key}",
        "Content-Type": "application/json",
    }
    
    payload = {
        "model": qwen_model,
        "messages": [{"role": "user", "content": prompt}],
        "max_tokens": 2048,
        "temperature": 0.7,
    }
    
    try:
        response = requests.post(
            "https://dashscope.aliyuncs.com/compatible-mode/v1/chat/completions",
            headers=headers,
            json=payload,
            timeout=60,
        )
        response.raise_for_status()
        result = response.json()
        if "choices" in result and len(result["choices"]) > 0:
            return result["choices"][0]["message"]["content"]
        return ""
    except Exception as e:
        return f"Error: {str(e)}"
$$;
EOSQL

snow sql -f /tmp/china_qwen_udf.sql --connection $SNOW_CONNECTION

# æµ‹è¯• Qwen UDF
echo ""
echo "ğŸ§ª Step 5: æµ‹è¯• Qwen UDF..."
snow sql -q "SELECT CORTEX_ANALYST_SEMANTICS.SEMANTIC_MODEL_GENERATOR.QWEN_COMPLETE('qwen-turbo', 'ä½ å¥½ï¼Œè¯·ç”¨ä¸€å¥è¯ä»‹ç»ä½ è‡ªå·±ã€‚');" --connection $SNOW_CONNECTION

# éƒ¨ç½² Streamlit åº”ç”¨
echo ""
echo "ğŸ“¤ Step 6: éƒ¨ç½² Streamlit åº”ç”¨æ–‡ä»¶..."
snow sql -f sis_setup/app_setup.sql --connection $SNOW_CONNECTION

echo ""
echo "=========================================="
echo "âœ… éƒ¨ç½²å®Œæˆ!"
echo "=========================================="
echo ""
echo "ğŸš€ æ‰“å¼€åº”ç”¨:"
echo "   snow streamlit get-url SEMANTIC_MODEL_GENERATOR --open \\"
echo "       --database cortex_analyst_semantics \\"
echo "       --schema semantic_model_generator \\"
echo "       --connection $SNOW_CONNECTION"
echo ""
echo "ğŸ“ æˆ–è€…åœ¨ Snowsight ä¸­æ‰“å¼€:"
echo "   1. ç™»å½• Snowsight"
echo "   2. å¯¼èˆªåˆ° Data > Databases > CORTEX_ANALYST_SEMANTICS"
echo "   3. æ‰¾åˆ° SEMANTIC_MODEL_GENERATOR schema"
echo "   4. ç‚¹å‡» Streamlit Apps > SEMANTIC_MODEL_GENERATOR"
echo ""
echo "âš ï¸  æ³¨æ„: å¦‚æœéœ€è¦æœ¬åœ°è¿è¡Œåº”ç”¨ï¼Œè¯·è®¾ç½®ä»¥ä¸‹ç¯å¢ƒå˜é‡:"
echo "   export USE_QWEN_FOR_CHINA=true"
echo "   export QWEN_API_KEY=$QWEN_API_KEY"
echo ""

